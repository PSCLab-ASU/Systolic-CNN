Systolic Array CNN	
This work presents a generic OpenCL-defined CNN accelerator architecture optimized for FPGA-based real-time analysis of images on edge.  CNN kernel design supports multiple CNN layers operations namely, convolution, LRN, average and max pooling, RELU and ETLWISE. 
1. How to use convolution kernel:
1.1.   Device code of convolution:
Convolution operation is divided into three kernels with three single-threaded memrd, mask_read and memwrite kernels to read the data from memory and write and autorun convolution kernel that performs the convolution. As name suggests memrd is used to read the input feature map, mask_read is used to read the weights and memwrite is used to write the final data to memory.  Three parameters defined for the convolution are namely, pe_num, reuse_fac and vec_fac. Vec_fac determines the SIMD width and is fixed to 16 ( that's why it is not mentioned in the code).  Reuse_fac determines the size of shift register used to store the input feature map in memrd kernel. Size of shift register is equal to reuse_fac x vec_fac.

1.1.1 Intel OpenCL channels
Intel OpenCL channels are used to transfers the data read from memory in mask_read , memread kernel to convolution kernel to perform multiply and accumulation (MAC) operation and send the final result to memwrite kernel to write the data to memory. Channel depths are determined based on the inital report generated by openCL compiler and can be changed to see the impact on the resources and performance. Channels mainly utilize the RAM Blocks. Structure type of channels are used to transer large amount of data from one kernel to other.

1.1.2 Common parameters
To generalize the convolution, all the parameters are send from the host side. Some of the parameters are common for each of the kernel and are explained below:
a. Input_height : Determines the value of output channel width divided by pe_num
b. Window : Number of times weight needs to shifted along the x dimension of the image and can be obtained by the equation :
          window = ceil[image_x_dimension/(stride* reuse_fac)]
c. Window2 : Number of times weight need to be shifted along the y dimension of the image and can be obtained by the equation :
        window2 = ceil[image_y_dimension/(stride)] 

d. Maskheight : Defines the y dimension of the weights. For fully connected (FC) layer , to use same kernels as convolution, maskheight is set to 1. 
e. Maskwidth  : Defines the x dimension of the weights. For FC layer, to use same kernels as convolution, maskwidth is kept as input_dimension/16, where 16 is vec_fac parameter and is fixed in the given design. 
f. Kernel_width : This parameters is determined by the input feature map channel dimesnion and vec_fac and is given by the equation:
           kernl_width = input_feature_map_channel_dimension/16

In the following section detailed information about the parameters related to each kernel is discussed

1.1.3 Memrd kernel features and parameters 
Memrd kernel is used to read input feature map for three major operations namely, convolution, FC, and max-pooling. Data is always read along the input feature map channel dimension that is per cycle, 16 data which is read from the memory is along the channel dimension and this read window moves along the x dimension till maskwidth parameter. Shift register based buffer is used here in memrd kernel to reuse the already read data. 
Effective reduction in the memory access is given the equation:
   memory_access_reduction = pe_num * reuse_fac*vec_fac.

Only difference between FC and convolution is explained above in  1.1.2 section. To determine if the layer is pooling or convolution , pool parameter is defined which is 1 for pooling layer and 0 for covolution layer.
Other parameters used are :
a. InputWidth : It is the x dimension of the input feature map
b. InputWidth2 : It is the y dimension of the input feature map
c. Stride_conv : Determines the stride along the y dimension of the input_feature_map and is given by the equation:
                 stride_conv = actual_stride
d. Stride_conv1 : Determines the stride along the x dimension of the input feature map and is given by the equation: 
                 stride_conv1 = (actual_stride > reuse_fac) ? actual_stride : reuse_fac         

e. Window_check : This parameter is used to enable support for the grouped convolution and is given by the equation:
         window_check = input_channel_dimension/group_parameter

Memrd kernel only send the data either to first convolution kernel or to the max_pooling kernel. As for convolution, we adopted 1-d Systolic array architecture, there is chain of channels which send convolution from one convolution kernel to next. This chain starts from the memrd kernel. 

1.1.4 Mask_read kernel features and parameters
Mask_read kernel is used to transfer the weights from the memory banks and send out the processing element to perform convolution. For convolution, number of weights required per cycle is given by the following equation:
               number_of_weights = vec_fac * pe_num
As mentioned earlier, vec_fac for our design is fixed to 16.  Convolution is more computationally expensive operation, it is not limited by the available memory bandwidth. However as same kernel is used for the Fully connected layer, which is memory intensive operation,  number of weights read from the memory is kept limited to vec_fac * pe_num / 4.  But the weights which are stored for FC are quantized and 4 weights are concatenated with each other from the host side. So, for example when 4 set pf weights are read from the memory by the device code, it can be converted to 16 different set of weight as shown in the code from 459-481. Now this different 16 set of weight can be transferred to 16 different PE. This quantization process is only used for Alexnet CNN, to mitigate the memory bandwidth limitation. But for resnet-50 and other bigger CNN, we have avoided using quantization process but still it can be used for bigger CNNs. 
To differentiate between FC and convolution layer , maskHeight is fixed to 1 for FC as has been done in memrd kernel. Other parameter which enables the quantizatiton logic is FC, which needs to be set to 1 for convolution and FC, however for quantized FC it needs to be set to 0. 
Other parameters used in mask_read kernel such as input_height, window, window2, maskwidth, kernel_width has similar defination as memrd kernels.

1.1.5 Convolution kernel features and parameters
Convolution kernels are used to perform the MAC operation on the data received from the memrd and mask_read kernel and send out the final result to mem_write kernel. Each of the convolution kernel is autorun kernel, thus they need to be instantiated from the host side, and is replicated pe_num times using num_compute_unit feature of OpenCL which generates 16 processing elements (PEs) of convolution kernel. As, our design using the concept of 1-d systolic array each PE sends out the input feature map to the adjacent one PE. However each PE receives different set of weights. Each PE also uses adder tree kind of structure to accumulate the final convolution result and send to mem_write kernel which can be seen from 684-688 lines of the code.  PE receives each paramter that is requires to perform convolution or FC is send via memory channel from memread kernel. So defination of the parameters such as input_height, kernel_width, mask_width, mask_height remains the same as defined in the memread kernel.


1.1.6 Memwrite kernel features and parameters
Memwrite kernel receives final convolution/FC results from the PE. Total size of the results received by the memwrite kernel is given by the following equation :
              total_size_results = pe_num * reuse_fac * data_bit_size.
 Since this collection from different PEs results in generation of MUX, to reduce the size of the MUX ( so as to reduce the output MUX), input data in Memread kernel per cycle is read along the channel dimension of the input feature map ( more information is available in the thesis). Bias addition and Sum layer( EltWise) is done in this kernel. Bias4 memory buffer is used for the sum layer and bias buffer is used for Bias addition to the convolution result. 
 Other paramters used in Memwrite kernels are used to determine the location where the output feature maps are stored in memory to be used by the following layers. Those parameters are defines below
        a. outputWidth = which determines the output dimension of the output feature maps.
        b. pad = which is used if the next layer requires padding of the feature maps.
        c. stride_write : as from each PE reuse_fac number of results are generated, but because of the stride there is a possibility
                          that these results cannot be used, this parameter is used to determine, of reuse_fac number of output, how                               many can be actually written into the memory. It is equal to the stride of the given convolution layer.
        
